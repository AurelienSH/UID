Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: 
that_omission ~ length_CC_onset + length_CC_remainder + position_matrix_verb +  
    subject_form_CC_subject1v2 + subject_form_CC_subject1v3 +  
    subject_form_CC_subject1v4 + frequency_CC_subject_head +  
    word_form_similarity + frequency_matrix_verb + matrix_subject1v2 +  
    matrix_subject1v3 + matrix_subject1v4 + data[[paste0("uid_",  
    uid_type)]] + (1 | m_verb)
   Data: data

     AIC      BIC   logLik deviance df.resid 
   543.4    601.6   -257.7    515.4      458 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.2313 -0.6711 -0.3656  0.8229  3.2607 

Random effects:
 Groups Name        Variance Std.Dev.
 m_verb (Intercept) 0        0       
Number of obs: 472, groups:  m_verb, 3

Fixed effects:
                                  Estimate Std. Error z value Pr(>|z|)    
(Intercept)                        5.61319    0.95480   5.879 4.13e-09 ***
length_CC_onset                    0.09033    0.03117   2.898  0.00375 ** 
position_matrix_verb              -0.01696    0.01236  -1.372  0.16993    
subject_form_CC_subject1v2         1.78314    0.91697   1.945  0.05182 .  
subject_form_CC_subject1v3         1.56719    0.52524   2.984  0.00285 ** 
subject_form_CC_subject1v4        -0.50918    0.43325  -1.175  0.23990    
frequency_CC_subject_head          0.05636    0.05727   0.984  0.32504    
word_form_similarity               1.96248    1.23203   1.593  0.11119    
frequency_matrix_verb              0.64946    0.10379   6.258 3.91e-10 ***
matrix_subject1v2                 -1.06647    0.64548  -1.652  0.09849 .  
matrix_subject1v3                 -0.49409    0.39763  -1.243  0.21402    
matrix_subject1v4                 -0.67206    0.29628  -2.268  0.02331 *  
data[[paste0("uid_", uid_type)]] -41.79285   26.87834  -1.555  0.11997    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
fit warnings:
fixed-effect model matrix is rank deficient so dropping 1 column / coefficient
Some predictor variables are on very different scales: consider rescaling
optimizer (Nelder_Mead) convergence code: 0 (OK)
boundary (singular) fit: see help('isSingular')

